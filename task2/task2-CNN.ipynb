{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1646455446078,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     },
     "user_tz": -480
    },
    "id": "GFBN6LlvgJOi",
    "outputId": "d88744e4-b95f-46ce-91dc-21d26f7c7454"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sat Mar  5 04:44:05 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   68C    P8    35W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!/opt/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24832,
     "status": "ok",
     "timestamp": 1646455566309,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     },
     "user_tz": -480
    },
    "id": "B4BMh4QAn5NY",
    "outputId": "46fc3fba-f18f-4a7c-8511-f1909af6674a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1646455582340,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     },
     "user_tz": -480
    },
    "id": "aLToKeOvhmas",
    "outputId": "24b61dec-f440-480b-d37d-9a6c488d0784"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acc1.png  data\timg  loss1.png\ttask2  task2-CNN.ipynb\n"
     ]
    }
   ],
   "source": [
    "! ls \"/content/drive/My Drive/nlp-beginner\""
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ],
   "metadata": {
    "id": "ZDzEY4ndL5uE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646455583174,
     "user_tz": -480,
     "elapsed": 4,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6592,
     "status": "ok",
     "timestamp": 1646455589764,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     },
     "user_tz": -480
    },
    "id": "uEhrs9CiiOwi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torchtext.vocab as Vocab\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import  torch.nn.functional as F\n",
    "\n",
    "\"\"\" 设置随机种子 \"\"\"\n",
    "torch.manual_seed(33)\n",
    "torch.cuda.manual_seed(33)\n",
    "np.random.seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1188,
     "status": "ok",
     "timestamp": 1646455590947,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     },
     "user_tz": -480
    },
    "id": "75woO3jii9-Z",
    "outputId": "02ac7901-b5f6-418f-c4c0-401323b8431b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchtext.vocab import vocab\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def save_img(loss, acc, test_acc):\n",
    "    num_epochs = len(loss)\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, test_acc, 'r', label='validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.figure()\n",
    "    plt.savefig(\"/content/drive/My Drive/nlp-beginner/acc1.png\")\n",
    "\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    # plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"/content/drive/My Drive/nlp-beginner/loss1.png\")\n",
    "\n",
    "\n",
    "def load_pretrained_embedding(words, pretrained_vocab):\n",
    "    \"\"\"从预训练好的vocab中提取出words对应的词向量\"\"\"\n",
    "    embed = torch.zeros(len(words), pretrained_vocab.vectors[0].shape[0]) # 初始化为0\n",
    "    oov_count = 0 # out of vocabulary\n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            idx = pretrained_vocab.stoi[word]\n",
    "            embed[i, :] = pretrained_vocab.vectors[idx]\n",
    "        except KeyError:\n",
    "            oov_count += 1\n",
    "    if oov_count > 0:\n",
    "        print(\"There are %d oov words.\" % oov_count)\n",
    "    return embed\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path, sep=\"\\t\")\n",
    "    print(\"data.shape: \", data.shape)  # (156060, 4)\n",
    "    # 提取句子与标签的列\n",
    "    x = data[\"Phrase\"]\n",
    "    y = data[\"Sentiment\"]\n",
    "    return x, torch.tensor(y)\n",
    "\n",
    "\n",
    "# 预处理文本：全部转小写、去除标点符号\n",
    "def pre_process(text):\n",
    "    text = text.lower()  # 转小写\n",
    "    # 去除标点符号\n",
    "    punctuation = '!,;:?.\"\\'、，；`'\n",
    "    text = re.sub(r'[{}]+'.format(punctuation), ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# 分词\n",
    "def get_tokenized_sent(sents):\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    def tokenizer(text):\n",
    "        words = word_tokenize(text)\n",
    "        words = [word.lower() for word in words\n",
    "                 if word.isalpha() and word not in stopWords]\n",
    "        return words\n",
    "    return [tokenizer(review) for review in sents]\n",
    "\n",
    "\n",
    "# 获得数据集的词典\n",
    "def get_vocab(sents):\n",
    "    tokenized_data = get_tokenized_sent(sents)\n",
    "    counter = collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "    min_feq = 3\n",
    "    idx = len(sorted_by_freq_tuples) - 1\n",
    "    while sorted_by_freq_tuples[idx][1] < min_feq:\n",
    "        sorted_by_freq_tuples.pop(idx)\n",
    "        idx -= 1\n",
    "    # 用<NOF>表示未找到的词\n",
    "    sorted_by_freq_tuples.append(('<NOF>', 1))\n",
    "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "    vocab_obj = vocab(ordered_dict)\n",
    "    return vocab_obj\n",
    "\n",
    "\n",
    "def words2id(vocab_dic, words):\n",
    "    def pad(x):\n",
    "        return x[:MAX_LEN] if len(x) > MAX_LEN else x + [0] * (MAX_LEN - len(x))\n",
    "\n",
    "    vec = []\n",
    "    not_found_id = len(vocab_dic) - 1\n",
    "    for word in words:\n",
    "        try:\n",
    "            vec.append(vocab_dic[word])\n",
    "        except KeyError:\n",
    "            vec.append(not_found_id)\n",
    "    return pad(vec)\n",
    "\n",
    "\n",
    "# 将句子转成长度一致的 词序号向量\n",
    "def preprocess_data(sents, vocab_dic, file_name):\n",
    "    tokenized_data = get_tokenized_sent(sents)\n",
    "    list = []\n",
    "    for words in tqdm(tokenized_data):\n",
    "        list.append(words2id(vocab_dic, words))\n",
    "    # np.save(file_name, np.array(list))\n",
    "    return torch.tensor(np.array(list))\n",
    "\n",
    "\n",
    "def get_sents_ids(file_path):\n",
    "    sents_ids = np.load(file_path).tolist()\n",
    "    return torch.tensor(sents_ids)\n",
    "\n",
    "\n",
    "def analysis_len(sents):\n",
    "    sents_len = [len(sent) for sent in sents]\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "    plt.figure(figsize=(30, 12), dpi=100)\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.title(\"句子长度分布\")\n",
    "    plt.hist(sents_len, bins=list(range(0, max(sents_len) + 1, 1)))\n",
    "    plt.xlabel('句子长度')\n",
    "    plt.ylabel('句子数量')\n",
    "    \"\"\" title 累计分布\"\"\"\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.title('累计分布图')\n",
    "    plt.hist(sents_len, bins=list(range(0, max(sents_len) + 1, 1)), cumulative=True)\n",
    "    plt.xlabel('句子长度')\n",
    "    plt.ylabel('累计比例(%)')\n",
    "    plt.savefig(\"sent_len.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def corr1d(X, K):\n",
    "    w = K.shape[0]\n",
    "    Y = torch.zeros((X.shape[0] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y[i] = (X[i: i + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "X, K = torch.tensor([0, 1, 2, 3, 4, 5, 6]), torch.tensor([1, 2])\n",
    "corr1d(X, K)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkEf72etAR7v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646455590947,
     "user_tz": -480,
     "elapsed": 8,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     }
    },
    "outputId": "8b282e12-03ad-4936-848b-906f253b4d95"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 2.,  5.,  8., 11., 14., 17.])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1646455590948,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     },
     "user_tz": -480
    },
    "id": "yiq-cdOznwJ2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "97f781d3-4269-484a-a159-8ef33d74952e"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 2.,  8., 14., 20., 26., 32.])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "def corr1d_multi_in(X, K):\n",
    "    # 首先沿着X和K的第0维（通道维）遍历并计算一维互相关结果。然后将所有结果堆叠起来沿第0维累加\n",
    "    return torch.stack([corr1d(x, k) for x, k in zip(X, K)]).sum(dim=0)\n",
    "\n",
    "X = torch.tensor([[0, 1, 2, 3, 4, 5, 6],\n",
    "              [1, 2, 3, 4, 5, 6, 7],\n",
    "              [2, 3, 4, 5, 6, 7, 8]])\n",
    "K = torch.tensor([[1, 2], [3, 4], [-1, -3]])\n",
    "corr1d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class GlobalMaxPool1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalMaxPool1d, self).__init__()\n",
    "    def forward(self, x):\n",
    "         # x shape: (batch_size, channel, seq_len)\n",
    "         # return shape: (batch_size, channel, 1)\n",
    "        return F.max_pool1d(x, kernel_size=x.shape[2])\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, kernel_sizes, num_channels):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        # 不参与训练的嵌入层\n",
    "        self.constant_embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.decoder = nn.Linear(sum(num_channels), 5)\n",
    "        # 时序最大池化层没有权重，所以可以共用一个实例\n",
    "        # self.pool = GlobalMaxPool1d()\n",
    "        self.convs = nn.ModuleList()  # 创建多个一维卷积层\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(in_channels = 2*embed_size, \n",
    "                                        out_channels = c, \n",
    "                                        kernel_size = k))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # 将两个形状是(批量大小, 词数, 词向量维度)的嵌入层的输出按词向量连结\n",
    "        embeddings = torch.cat((\n",
    "            self.embedding(inputs), \n",
    "            self.constant_embedding(inputs)), dim=2) # (batch, seq_len, 2*embed_size)\n",
    "        # 根据Conv1D要求的输入格式，将词向量维，即一维卷积层的通道维(即词向量那一维)，变换到前一维\n",
    "        embeddings = embeddings.permute(0, 2, 1)\n",
    "        # 对于每个一维卷积层，在时序最大池化后会得到一个形状为(批量大小, 通道大小, 1)的\n",
    "        # Tensor。使用flatten函数去掉最后一维，然后在通道维上连结\n",
    "        # encoding = torch.cat([self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\n",
    "        encoding = torch.cat([F.relu(conv(embeddings)).squeeze(-1) for conv in self.convs], dim=1)\n",
    "        # 应用丢弃法后使用全连接层得到输出\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs\n"
   ],
   "metadata": {
    "id": "3a9RlWvXAcZi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646455691684,
     "user_tz": -480,
     "elapsed": 4,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_path = \"/content/drive/My Drive/nlp-beginner\"\n",
    "\n",
    "num_hiddens = 100\n",
    "num_layers = 1\n",
    "lr = 0.005\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "MAX_LEN = 30  # 将每条评论通过截断或者补0，使得长度变成500\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "embed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n",
    "\n",
    "DATA_ROOT = data_path + \"/data\"\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=embed_size, cache=os.path.join(DATA_ROOT, \"glove\"))"
   ],
   "metadata": {
    "id": "IB7334Qe1BR2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646455698147,
     "user_tz": -480,
     "elapsed": 4526,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     }
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_path = data_path + \"/data/train2.tsv\"\n",
    "# train_path = data_path + \"/data/data.tsv\"\n",
    "\n",
    "test_path = data_path + \"/data/test2.tsv\"\n",
    "train_sents, train_labels = load_data(train_path)\n",
    "test_sents, test_labels = load_data(test_path)\n",
    "\n",
    "# from data_process import analysis_len\n",
    "# analysis_len([sent.split() for sent in train_sents])\n",
    "\n",
    "\n",
    "x = pd.concat([train_sents, test_sents])\n",
    "y = torch.cat((train_labels, test_labels), -1)\n",
    "train_sents, test_sents, train_labels, test_labels = train_test_split(x, y, test_size=0.2)\n",
    "vocab = get_vocab(x)\n",
    "vocab_dic = vocab.get_stoi()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTZkeTdx5QXR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646455718366,
     "user_tz": -480,
     "elapsed": 20233,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     }
    },
    "outputId": "e7bb4ec4-a227-4e8d-be09-ce9b240a6c45"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data.shape:  (126874, 4)\n",
      "data.shape:  (29186, 4)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "RAn8TpidhdEF",
    "executionInfo": {
     "status": "error",
     "timestamp": 1646455746673,
     "user_tz": -480,
     "elapsed": 28327,
     "user": {
      "displayName": "J Goke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13735326768258159081"
     }
    },
    "outputId": "0da8953f-e567-4774-f828-2bee2d4cc523"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# words in vocab: 14533\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 124848/124848 [00:00<00:00, 223422.58it/s]\n",
      "100%|██████████| 31212/31212 [00:00<00:00, 265861.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 300 oov words.\n",
      "There are 300 oov words.\n",
      "training on  cuda:0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/488 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-0612460cbc77>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"__main__\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 105\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-13-0612460cbc77>\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     99\u001B[0m                                         model.parameters()), lr=lr)\n\u001B[1;32m    100\u001B[0m     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCrossEntropyLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 101\u001B[0;31m     \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    102\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-13-0612460cbc77>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(train_iter, test_iter, net, loss, optimizer, device, num_epochs)\u001B[0m\n\u001B[1;32m     12\u001B[0m             \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m             \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m             \u001B[0my_hat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m             \u001B[0ml\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_hat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-10-a13afada6761>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0;31m# Tensor。使用flatten函数去掉最后一维，然后在通道维上连结\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[0;31m# encoding = torch.cat([self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m         \u001B[0mencoding\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mconv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvs\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m         \u001B[0;31m# 应用丢弃法后使用全连接层得到输出\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Expected size 28 but got size 27 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "def train(train_iter, test_iter, net, loss, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    batch_count = 0\n",
    "    loss_epochs = []\n",
    "    acc_epochs = []\n",
    "    test_acc_epochs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        process_bar = tqdm(train_iter)\n",
    "        for (X, y) in process_bar:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 0.5)   # 梯度裁剪\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        loss_epochs.append(train_l_sum / batch_count)\n",
    "        acc_epochs.append(train_acc_sum / n)\n",
    "        test_acc_epochs.append(test_acc)\n",
    "        # test_loss = compute_loss(test_iter, net, loss, device)\n",
    "        print('epoch %d, train loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
    "    save_img(loss_epochs, acc_epochs, test_acc_epochs)\n",
    "\n",
    "\n",
    "def compute_loss(data_iter, net, loss, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    loss_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # net.eval() # 评估模式, 这会关闭dropout\n",
    "            y_hat = net(X)\n",
    "            loss_sum += loss(y_hat, y).cpu().item()\n",
    "            # net.train() # 改回训练模式\n",
    "            n += y.shape[0]\n",
    "    return loss_sum / n\n",
    "\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item()\n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "\n",
    "def main():\n",
    "    print('# words in vocab:', len(vocab))\n",
    "    train_input_file = data_path + \"/train_input3.npy\"\n",
    "    test_input_file = data_path + \"/test_input3.npy\"\n",
    "\n",
    "    train_input = preprocess_data(train_sents, vocab_dic, train_input_file)\n",
    "    test_input = preprocess_data(test_sents, vocab_dic, test_input_file)\n",
    "\n",
    "    # train_input = get_sents_ids(train_input_file)\n",
    "    train_set = TensorDataset(train_input, train_labels)\n",
    "    train_loader = DataLoader(train_set, batch_size, shuffle=True)\n",
    "    # test_input = get_sents_ids(test_input_file)\n",
    "    test_set = TensorDataset(test_input, test_labels)\n",
    "    test_loader = DataLoader(test_set, batch_size)\n",
    "\n",
    "    # 创建网络\n",
    "    model = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)\n",
    "    # 加载Glove词向量\n",
    "    vocab_list = vocab.get_itos()\n",
    "    model.embedding.weight.data.copy_(\n",
    "        load_pretrained_embedding(vocab_list, glove_vocab))\n",
    "    model.constant_embedding.weight.data.copy_(\n",
    "        load_pretrained_embedding(vocab_list, glove_vocab))\n",
    "    model.constant_embedding.weight.requires_grad = False\n",
    "    \n",
    "    # 要过滤掉不计算梯度的embedding参数\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,\n",
    "                                        model.parameters()), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    train(train_loader, test_loader, model, loss, optimizer, device, num_epochs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHDRCo4Zs7OM"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "task2-CNN.ipynb",
   "provenance": [],
   "mount_file_id": "1wa_7HseWhkSW9kvMezju6El-Bgqw9_2j",
   "authorship_tag": "ABX9TyMS5cPIFPO0OKaiXDZoDAHD"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}